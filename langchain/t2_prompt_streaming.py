from langchain_ollama import ChatOllama


class LangClient:
    """Class to create ChatOllama client"""

    def __init__(
        self, base_url="http://localhost:11434", model="llama3.2", temparature=0
    ):
        self.base_url = base_url
        self.model = model
        self.llm = ChatOllama(
            base_url=base_url, model=model, temperature=temparature
        )

    def stream_prompt(self, prompt):
        """Method to stream the response generated by the LLM for a given prompt."""
        return self.llm.stream(prompt)


if __name__ == "__main__":

    prompt = "Tell me about the differrent types of wildlife found in Western Ghats of southern India"

    client = LangClient()
    for chunk in client.stream_prompt(prompt):
        print(chunk.content, end="")
